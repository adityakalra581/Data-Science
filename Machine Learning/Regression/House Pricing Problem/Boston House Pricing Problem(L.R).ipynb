{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Boston House Pricing Problem:\n",
    "\n",
    "The Boston Housing Dataset consists of price of houses in various places in Boston. Alongside with price, the dataset also provide information such as **Crime (CRIM)**, areas of non-retail business in the town **(INDUS)**, the age of people who own the house **(AGE)**, and there are many other attributes that available in it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bh.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                  # Indicates warnings specifically for obsolete module.\n",
    "warnings.filterwarnings(\"ignore\")                # Read more: https://docs.python.org/3/library/warnings.html\n",
    "\n",
    "from sklearn.datasets import load_boston    # For loading the dataset.(It is in-built in scikit-learn)\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "# For reading the csv file\n",
    "from csv import reader\n",
    " # For complicated Square root problems\n",
    "from math import sqrt \n",
    "\n",
    "# For data manipulation\n",
    "import pandas as pd                         \n",
    "import numpy as np\n",
    "\n",
    "# For data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For using linear regression(prediction)\n",
    "from sklearn.linear_model import SGDRegressor   ## SGD = stochastic grad. descent\n",
    "\n",
    "# for using scalers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score\n",
    "from numpy import random\n",
    "\n",
    "# for training and testing of data\n",
    "from sklearn.model_selection import train_test_split                   \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV   \n",
    "from sklearn.model_selection import StratifiedKFold                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV: changing the training and testing data ratios continuosly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split: ( 80% = train and 20% = test)\n",
    "\n",
    "scikit-learn provides a helpful function for partitioning data, train_test_split , which splits out your data into a training set and a test set. We provide the proportion of data to use as a test set and we can provide the parameter **random_state , which is a seed to ensure repeatable results**.  \n",
    "\n",
    "train_test_split splits arrays or matrices into random train and test subsets. That means that everytime you run it without **specifying random_state , you will get a different result, this is expected behavior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Read the data and see how it Looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\aditya\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston=load_boston()                                                    \n",
    "boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements Visible From above trash.\n",
    "\n",
    "**data**: contains the information for various houses\n",
    "\n",
    "**target**: prices of the house\n",
    "\n",
    "**feature_names**: names of the features\n",
    "\n",
    "**DESCR**: describes the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organising The Data\n",
    "\n",
    "For a human to read and analyse it properly we need to convert this data into a **dataframe** using **Pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data=pd.DataFrame(load_boston().data,columns=load_boston().feature_names)\n",
    "Y=load_boston().target\n",
    "X=load_boston().data\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=10)        \n",
    "boston_data.head()                                                   \n",
    "#x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Explanation:\n",
    "\n",
    "**CRIM**: Per capita crime rate by town\n",
    "\n",
    "**ZN**: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "\n",
    "**INDUS**: Proportion of non-retail business acres per town\n",
    "\n",
    "**CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "**NOX**: Nitric oxide concentration (parts per 10 million)\n",
    "\n",
    "**RM**: Average number of rooms per dwelling\n",
    "\n",
    "**AGE**: Proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "**DIS**: Weighted distances to five Boston employment centers\n",
    "\n",
    "**RAD**: Index of accessibility to radial highways\n",
    "\n",
    "**TAX**: Full-value property tax rate per $10,000\n",
    "\n",
    "**PTRATIO**: Pupil-teacher ratio by town\n",
    "\n",
    "**B**: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
    "\n",
    "**LSTAT**: Percentage of lower status of the population\n",
    "\n",
    "**MEDV**: Median value of owner-occupied homes in $1000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing The Data:\n",
    "\n",
    "Description Of the data will provide us every basic mathematical details regarding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation of Data:\n",
    "\n",
    "The main purpose of **normalization** is to minimize the **redundancy** and remove Insert, Update and Delete Anomaly. It divides larger tables to smaller tables and links them using relationships. Data redundancy happens when the same piece of data is held in two separate place.\n",
    "\n",
    "In the simplest cases, normalization of ratings means adjusting values measured on **different scales** to a notionally common scale, often prior to averaging. Some types of normalization involve only a rescaling, to arrive at values relative to some size variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALING  V/S  NORMALISATION\n",
    "\n",
    "In both cases, you're transforming the values of numeric variables so that the transformed data points have specific helpful properties. The difference is that, in $scaling$, you're changing the $range$ of your data while in **normalization** you're changing the shape of the **distribution** of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW SCALING IS DONE?\n",
    "\n",
    "$solution$: Using **Scalers**.\n",
    "\n",
    "Many machine learning algorithms work better when features are on a relatively similar scale and close to normally distributed. $MinMaxScaler$, $RobustScaler$, $StandardScaler$, and **Normalizer** are scikit-learn methods to preprocess data for machine learning. Which method you need, if any, depends on your model type and your feature values.\n",
    "\n",
    "### Standard Scaler: (used in this problem)\n",
    "\n",
    "The idea behind **StandardScaler** is that it will transform your data such that its distribution will have a **mean value 0** and **standard deviation of 1** . Given the distribution of the data, each value in the dataset will have the sample mean value subtracted, and then divided by the standard deviation of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler().fit(x_train)      \n",
    "x_train= scaler.transform(x_train)                        \n",
    "x_test= scaler.transform(x_test)  \n",
    "\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideally:\n",
    "\n",
    "Standard scaler should give mean =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.272748602865857e-15\n",
      "-0.03307416532420048\n"
     ]
    }
   ],
   "source": [
    "print(x_train.mean())\n",
    "print(x_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a data frame for training data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.416498</td>\n",
       "      <td>-0.470884</td>\n",
       "      <td>-1.242215</td>\n",
       "      <td>-0.244704</td>\n",
       "      <td>-0.965870</td>\n",
       "      <td>2.717928</td>\n",
       "      <td>0.247011</td>\n",
       "      <td>-0.137704</td>\n",
       "      <td>-0.884200</td>\n",
       "      <td>-0.813324</td>\n",
       "      <td>-0.262071</td>\n",
       "      <td>0.449709</td>\n",
       "      <td>-1.244567</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.389588</td>\n",
       "      <td>-0.470884</td>\n",
       "      <td>1.491518</td>\n",
       "      <td>-0.244704</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>1.065696</td>\n",
       "      <td>-0.788055</td>\n",
       "      <td>-0.659581</td>\n",
       "      <td>0.123170</td>\n",
       "      <td>1.224527</td>\n",
       "      <td>0.430023</td>\n",
       "      <td>-0.052406</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.412719</td>\n",
       "      <td>-0.470884</td>\n",
       "      <td>0.946211</td>\n",
       "      <td>-0.244704</td>\n",
       "      <td>0.488697</td>\n",
       "      <td>-1.423651</td>\n",
       "      <td>1.008495</td>\n",
       "      <td>-0.796464</td>\n",
       "      <td>1.586611</td>\n",
       "      <td>1.455201</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>-0.052194</td>\n",
       "      <td>1.696760</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.416498 -0.470884 -1.242215 -0.244704 -0.965870  2.717928  0.247011   \n",
       "1 -0.389588 -0.470884  1.491518 -0.244704  0.574767  0.304878  1.065696   \n",
       "2  1.412719 -0.470884  0.946211 -0.244704  0.488697 -1.423651  1.008495   \n",
       "\n",
       "          7         8         9        10        11        12  price  \n",
       "0 -0.137704 -0.884200 -0.813324 -0.262071  0.449709 -1.244567   38.7  \n",
       "1 -0.788055 -0.659581  0.123170  1.224527  0.430023 -0.052406   19.2  \n",
       "2 -0.796464  1.586611  1.455201  0.759965 -0.052194  1.696760   12.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.DataFrame(x_train)\n",
    "train_data['price']=y_train\n",
    "train_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "linear regression is an approach for predicting a **quantitative response** using a **single/multiple feature(s)** (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "Here:\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**. \n",
    "\n",
    "Similarily For Multiple Linear Regression:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "This is called **multiple linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](slope_intercept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply Linear Regression now?\n",
    "### Solution = SGDRegressor\n",
    "\n",
    "SGD stands for **Stochastic Gradient Descent**: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm **L2** or the absolute norm **L1** or a combination of both $(Elastic Net)$. If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.\n",
    "\n",
    "This implementation works with data represented as dense numpy arrays of floating point values for the features.\n",
    "\n",
    "**Gradient descent** : Gradient descent is a first-order iterative optimization algorithm for finding the **minimum of a function.** To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.\n",
    "\n",
    "\n",
    "To read more about SGDRegressor and gradient descent refer:https://kite.com/python/docs/sklearn.linear_model.stochastic_gradient.SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](gd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Cost-Function.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Structure of SGDRegressor\n",
    "\n",
    "#  SGDRegressor(\n",
    "# loss: str=builtins.str,\n",
    "# penalty: str=builtins.str,\n",
    "# alpha: float=0.0001,\n",
    "# l1_ratio: float=0.15,\n",
    "# fit_intercept: bool=True,\n",
    "# max_iter: int=1000,\n",
    "# tol: float=0.001,\n",
    "# shuffle: bool=True,\n",
    "# verbose: int=0,\n",
    "# epsilon: float=0.1,\n",
    "# random_state: NoneType=None,\n",
    "# learning_rate: str=builtins.str,\n",
    "# eta0: float=0.01,\n",
    "# power_t: float=0.25,\n",
    "# early_stopping: bool=False,\n",
    "# validation_fraction: float=0.1,\n",
    "# n_iter_no_change: int=5,\n",
    "# warm_start: bool=False,\n",
    "# average: bool=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 42.9418661266653\n",
      "mean Absolute error: 4.853651048520283\n",
      "R squared 0.5601726836579701\n"
     ]
    }
   ],
   "source": [
    "#Sklearn SGD classifier\n",
    "clf_= SGDRegressor(alpha=0.8,l1_ratio=0.3,eta0=0.04,\n",
    "                   learning_rate='constant',loss='squared_loss',fit_intercept=True,random_state=10)\n",
    "\n",
    "\n",
    "clf_.fit(x_train, y_train)  \n",
    "\n",
    "# Scatter plot command\n",
    "plt.scatter(y_test,clf_.predict(x_test))     \n",
    "\n",
    "# for grid lines\n",
    "plt.grid()                                  \n",
    "\n",
    "# label and titles(Just like matlab)\n",
    "plt.xlabel('Actual y')                  \n",
    "plt.ylabel('predicted y')\n",
    "plt.title('scatter plot between actual y and predictd y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('mean squared error:',mean_squared_error(y_test,clf_.predict(x_test)))\n",
    "print('mean Absolute error:',mean_absolute_error(y_test,clf_.predict(x_test)))\n",
    "print('R squared',r2_score(y_test,clf_.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23960892,  0.09928655,  0.55695093, -0.41379755, -0.22346783,\n",
       "        2.25934098,  0.45606934, -1.03719009,  0.30224012, -0.07532755,\n",
       "       -1.18277506,  0.65481216, -2.41821842])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff=clf_.coef_\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
